{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezA8Ai5-0fVU"
      },
      "source": [
        "#### Linear Regression By Abhijit Challapalli"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBhoosWU0593",
        "outputId": "f7d9913f-4326-4ece-c10a-7c9ed54d844f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BugTOfuE0fVW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso,ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold,GridSearchCV\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5DuTYdR0fVZ",
        "outputId": "40f6a0f9-07c5-4f1b-d1f4-79a6277f2d1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0    -122.23     37.88                  41          880           129.0   \n",
            "1    -122.22     37.86                  21         7099          1106.0   \n",
            "2    -122.24     37.85                  52         1467           190.0   \n",
            "3    -122.25     37.85                  52         1274           235.0   \n",
            "4    -122.25     37.85                  52         1627           280.0   \n",
            "\n",
            "   population  households  median_income ocean_proximity  median_house_value  \n",
            "0         322         126         8.3252        NEAR BAY              452600  \n",
            "1        2401        1138         8.3014        NEAR BAY              358500  \n",
            "2         496         177         7.2574        NEAR BAY              352100  \n",
            "3         558         219         5.6431        NEAR BAY              341300  \n",
            "4         565         259         3.8462        NEAR BAY              342200  \n",
            "(20640, 10)\n",
            "(20640, 9)\n",
            "(20640,)\n"
          ]
        }
      ],
      "source": [
        "#1. Load and Explore Data:\n",
        "#- Read the \"housing.xlsx\" file.\n",
        "#- Display the first few rows of the dataset.\n",
        "#- Extract input (X) and output (Y) data from the dataset.\n",
        "housing_df = pd.read_csv('/content/drive/MyDrive/housing.csv')\n",
        "print(housing_df.head())\n",
        "print(housing_df.shape)\n",
        "\n",
        "x = housing_df.drop(columns=['median_house_value'])\n",
        "y = housing_df['median_house_value']\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuJPycMg0fVb"
      },
      "outputs": [],
      "source": [
        "#2. Handle Missing Values:\n",
        "#- Fill missing values. Imputation method should make sense.\n",
        "housing_df.isnull().sum()\n",
        "\n",
        "# using the median strategy with simple imputation\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Fit and transform the total_bedrooms column\n",
        "housing_df['total_bedrooms'] = imputer.fit_transform(housing_df[['total_bedrooms']])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtdLo5Sm0fVb"
      },
      "source": [
        "#### Since the data in total_bedrooms feature is right skewed, using the median imputation strategy might be better than using the mean, as the median is more robust to extreme values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6f1t4a90fVc",
        "outputId": "05d5d6fa-7ed2-402e-ad84-f9d8c9e5e511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           20640 non-null  float64\n",
            " 1   latitude            20640 non-null  float64\n",
            " 2   housing_median_age  20640 non-null  int64  \n",
            " 3   total_rooms         20640 non-null  int64  \n",
            " 4   total_bedrooms      20640 non-null  float64\n",
            " 5   population          20640 non-null  int64  \n",
            " 6   households          20640 non-null  int64  \n",
            " 7   median_income       20640 non-null  float64\n",
            " 8   ocean_proximity     20640 non-null  object \n",
            " 9   median_house_value  20640 non-null  int64  \n",
            "dtypes: float64(4), int64(5), object(1)\n",
            "memory usage: 1.6+ MB\n",
            "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0    -122.23     37.88                  41          880           129.0   \n",
            "1    -122.22     37.86                  21         7099          1106.0   \n",
            "2    -122.24     37.85                  52         1467           190.0   \n",
            "3    -122.25     37.85                  52         1274           235.0   \n",
            "4    -122.25     37.85                  52         1627           280.0   \n",
            "\n",
            "   population  households  median_income  ocean_proximity  median_house_value  \n",
            "0         322         126         8.3252                3              452600  \n",
            "1        2401        1138         8.3014                3              358500  \n",
            "2         496         177         7.2574                3              352100  \n",
            "3         558         219         5.6431                3              341300  \n",
            "4         565         259         3.8462                3              342200  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "#3. Encode Categorical Data:\n",
        "#- Convert categorical columns in the dataset to numerical data.\n",
        "\n",
        "housing_df.info()\n",
        "label = LabelEncoder()\n",
        "housing_df['ocean_proximity'] = label.fit_transform(housing_df[['ocean_proximity']])\n",
        "print(housing_df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4gzX83L0fVc",
        "outputId": "dd42d321-6be6-4a3e-a37d-2478a1c15932",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16512, 9)\n",
            "(4128, 9)\n",
            "(4128,)\n",
            "(16512,)\n"
          ]
        }
      ],
      "source": [
        "#4. Split the Dataset:\n",
        "#- Split the data into 80% training dataset and 20% test dataset\n",
        "x = housing_df.drop(columns=['median_house_value'])\n",
        "y = housing_df['median_house_value']\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state= 10)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3HeNFUS0fVd",
        "outputId": "b578695b-18b2-42d3-c804-314f96a49ce9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.18192367, -0.67849302, -1.34840706, ..., -1.00916727,\n",
              "         0.71293818,  1.96551927],\n",
              "       [-1.38943917,  0.9181829 , -0.14117516, ...,  0.88878716,\n",
              "         0.03727867,  1.96551927],\n",
              "       [ 0.88979   , -0.90928099, -1.34840706, ...,  1.21103343,\n",
              "         0.31517798, -0.82796103],\n",
              "       ...,\n",
              "       [-1.40450016,  1.12071111,  0.34171759, ..., -0.18705867,\n",
              "         0.03991695,  1.26714919],\n",
              "       [ 0.63375324, -0.76327227,  1.30750311, ..., -0.34437575,\n",
              "        -1.53456991, -0.82796103],\n",
              "       [ 0.67391587, -0.65494323,  0.90509248, ..., -0.70214523,\n",
              "         2.03683973, -0.82796103]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\n",
        "#5. Standardize Data:\n",
        "#- Standardize the training and test datasets\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.fit_transform(x_test)\n",
        "\n",
        "x_train_scaled\n",
        "x_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaEgp2Xx0fVd",
        "outputId": "8f87a05b-58b2-4a78-884a-1f77cad5a430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[277317.06686109 274032.58208745 263316.78296738 ... 224587.26169117\n",
            " 113353.56280082 368871.93725691]\n",
            "Linear Regression RMSE: 70559.92223637385\n"
          ]
        }
      ],
      "source": [
        "#6. Linear Regression:\n",
        "#- Perform Linear Regression on the training data.\n",
        "#- Predict the output for the test dataset using the fitted model.\n",
        "#- Print the root mean squared error (RMSE) from Linear Regression.\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(x_train_scaled,y_train)\n",
        "\n",
        "linear_pred = linear_reg.predict(x_test_scaled)\n",
        "print(linear_pred)\n",
        "\n",
        "linear_rmse = np.sqrt(mean_squared_error(y_test,linear_pred))\n",
        "print(\"Linear Regression RMSE:\",linear_rmse)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggQJgGcu0fVe",
        "outputId": "0686ac95-287e-45c5-cfe2-7b9601fe66c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[277314.87396588 274028.5801481  263312.50983532 ... 224586.55092893\n",
            " 113354.8325373  368870.9012924 ]\n",
            "Lasso Regression RMSE: 70560.00003923356\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#7. Lasso Regression:\n",
        "#- Implement Lasso Regression on the training data.\n",
        "#- Predict the output for the test dataset using the fitted Lasso model.\n",
        "#- Evaluate and print the RMSE for Lasso Regression.\n",
        "lasso_regression = Lasso(alpha=0.3)\n",
        "lasso_regression.fit(x_train_scaled,y_train)\n",
        "\n",
        "lasso_predict = lasso_regression.predict(x_test_scaled)\n",
        "print(lasso_predict)\n",
        "\n",
        "lasso_rmse = np.sqrt(mean_squared_error(y_test,lasso_predict))\n",
        "print(\"Lasso Regression RMSE:\",lasso_rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJcVPU6d0fVf",
        "outputId": "44f0a1df-ee01-450a-bc78-5c4ffffdd62f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[277306.26563042 274021.42830044 263307.23971625 ... 224584.68522079\n",
            " 113351.07837298 368874.02079982]\n",
            "Ridge Regression RMSE: 70559.96740390857\n"
          ]
        }
      ],
      "source": [
        "#8. Ridge Regression:\n",
        "#- Implement Ridge Regression on the training data.\n",
        "#- Predict the output for the test dataset using the fitted Ridge model.\n",
        "#- Evaluate and print the RMSE for Ridge Regression.\n",
        "ridge_regression = Ridge(alpha=0.3)\n",
        "ridge_regression.fit(x_train_scaled,y_train)\n",
        "ridge_predict = ridge_regression.predict(x_test_scaled)\n",
        "print(ridge_predict)\n",
        "ridge_rmse = np.sqrt(mean_squared_error(y_test,ridge_predict))\n",
        "print(\"Ridge Regression RMSE:\",ridge_rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMTe9DoM0fVg",
        "outputId": "9003d903-bbfe-4826-b97c-41f9c5aba81a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[250058.88612489 240900.79682736 230262.2291075  ... 217722.44822775\n",
            " 120361.52985551 354560.25505993]\n",
            "Elastic Net Regression RMSE: 75927.58639581053\n"
          ]
        }
      ],
      "source": [
        "#9. Elastic Net Regression:\n",
        "#- Implement Elastic Net Regression on the training data.\n",
        "#- Predict the output for the test dataset using the fitted Elastic Net model.\n",
        "#- Evaluate and print the RMSE for Elastic Net Regression.\n",
        "elastic_regression = ElasticNet(alpha=0.3, l1_ratio= 0.5)\n",
        "elastic_regression.fit(x_train_scaled,y_train)\n",
        "elastic_predict = elastic_regression.predict(x_test_scaled)\n",
        "print(elastic_predict)\n",
        "elastic_rmse = np.sqrt(mean_squared_error(y_test,elastic_predict))\n",
        "print(\"Elastic Net Regression RMSE:\",elastic_rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEEjyCo-0fVh",
        "outputId": "314eee24-e26c-475a-a545-453e4074c911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression Model Cross-Validation RMSE: 69594.53595245\n",
            "Lasso Regression Model Cross-Validation RMSE: 69594.60268664401\n",
            "Elastic Net Regression Cross-Validation RMSE: 74517.0198212744\n"
          ]
        }
      ],
      "source": [
        "#10. Cross-Validation and Grid Search:\n",
        "#- Apply cross-validation on the dataset to assess the models' generalization performance.\n",
        "#- Perform grid search to fine-tune hyperparameters for Ridge and Lasso Regression models.\n",
        "#- Discuss the results of cross-validation and grid search, providing insights into the optimal hyperparameters for the models\n",
        "\n",
        "# Perform cross-validation for Ridge Regression Model\n",
        "ridge_cross = cross_val_score(Ridge(alpha=0.3), x_train_scaled, y_train, cv=10, scoring='neg_mean_squared_error')\n",
        "ridge_cv_rmse = np.sqrt(-ridge_cross.mean())\n",
        "print(\"Ridge Regression Model Cross-Validation RMSE:\",ridge_cv_rmse)\n",
        "\n",
        "# Perform cross-validation for Lasso Regression Model\n",
        "lasso_cross = cross_val_score(Lasso(alpha=0.3), x_train_scaled, y_train, cv=10, scoring='neg_mean_squared_error')\n",
        "lasso_cv_rmse = np.sqrt(-lasso_cross.mean())\n",
        "print(\"Lasso Regression Model Cross-Validation RMSE:\",lasso_cv_rmse)\n",
        "\n",
        "\n",
        "# Perform cross-validation for Elastic Net Regression\n",
        "elastic_net_cv_scores = cross_val_score(ElasticNet(alpha=0.3, l1_ratio=0.5), x_train_scaled, y_train, cv=10, scoring='neg_mean_squared_error')\n",
        "elastic_net_cv_rmse = np.sqrt(-elastic_net_cv_scores.mean())\n",
        "print(\"Elastic Net Regression Cross-Validation RMSE:\", elastic_net_cv_rmse)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY_IqxsV0fVh"
      },
      "source": [
        "##### Since Linear regression, being a simple and interpretable model, which tends to have lower variance and is less likely to overfit the training data compared to more complex models.So, Cross-validation was only performed for RIdge,Lasso and Elastic Regression Models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLTFvQb30fVi",
        "outputId": "f5f5f6d9-9e2e-4b4e-a971-972da817a9a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
            "{'alpha': 10.0}\n",
            "69595.83234708985\n"
          ]
        }
      ],
      "source": [
        "# Grid Search\n",
        "fold = KFold(n_splits=10, shuffle=True, random_state=10)\n",
        "parameters = {'alpha':[0.001,0.01,0.1,0.2,0.5,0.9,1.0,5.0,10.0]}\n",
        "model_cv_ridge = GridSearchCV(estimator=ridge_regression,\n",
        "                            param_grid=parameters,\n",
        "                            scoring='neg_mean_squared_error',\n",
        "                            cv=fold,\n",
        "                            return_train_score=True,\n",
        "                            verbose=1)\n",
        "model_cv_ridge.fit(x_train_scaled,y_train)\n",
        "print(model_cv_ridge.best_params_)\n",
        "ridge_grid_rmse = np.sqrt(-model_cv_ridge.best_score_)\n",
        "print(ridge_grid_rmse)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE2P9yMy0fVi",
        "outputId": "548886f2-2a26-49f1-ae93-c79628ffd339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
            "{'alpha': 10.0}\n",
            "69597.33594758525\n"
          ]
        }
      ],
      "source": [
        "model_cv_lasso = GridSearchCV(estimator=lasso_regression,\n",
        "                            param_grid=parameters,\n",
        "                            scoring='neg_mean_squared_error',\n",
        "                            cv=fold,\n",
        "                            return_train_score=True,\n",
        "                            verbose=1)\n",
        "model_cv_lasso.fit(x_train_scaled,y_train)\n",
        "print(model_cv_lasso.best_params_)\n",
        "lasso_grid_rmse = np.sqrt(-model_cv_lasso.best_score_)\n",
        "print(lasso_grid_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szoC8SMK0fVj"
      },
      "source": [
        "#### Interpretations for Cross-Validation\n",
        "\n",
        "##### The findings demonstrate that the performance of the Ridge and Lasso regression models is relatively close, with Ridge having a little lower RMSE. This implies that both models are capable of providing a good fit to the data while avoiding overfitting.\n",
        "\n",
        "##### The Elastic Net regression model is more prone to overfitting and has a lower accuracy due to its larger RMSE. This might be the result of the fact that Elastic Net regression requires an additional hyperparameter called l1_ratio, which regulates the ratio between the two regularization techniques.\n",
        "\n",
        "##### Elastic Net regression is a hybrid of Lasso and Ridge. The model may not work well if the l1_ratio is not optimized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G32ePCDd0fVj"
      },
      "source": [
        "##### -----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9CHXzQW0fVj"
      },
      "source": [
        "#### Interpretations for Grid Search\n",
        "##### According to the findings, both the Ridge and Lasso regression models benefit from a moderate level of regularization, with an ideal alpha value of 10.0 for both. Each model's top score is marginally better than the cross-validation RMSE, indicating some improvement in the models' performance due to the grid search.\n",
        "\n",
        "##### The best score for Ridge regression is likewise marginally lower than the best score for Lasso regression, indicating that even with hyperparameter adjustment, Ridge regression is marginally superior to Lasso regression."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "0.0.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}